{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MP3_BOUZIANE_Mostafa.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2pRyIuLYFUI0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "metadata": {
        "id": "3J-jtt_nAVQW",
        "colab_type": "code",
        "outputId": "e18e4ade-1814-4ec2-8de2-7c12adf0ba2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo pip install scikit-video"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->scikit-video) (0.46)\n",
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->scikit-video) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-1cqQ8DYFUI1",
        "colab_type": "code",
        "outputId": "29eb9bb4-b266-4a54-9124-66c38ad24cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd,Adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization,Flatten\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aHCZFTuNFUI9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "oxj0otSVFUJB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "metadata": {
        "id": "JFvQ4UhhFUJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Context"
      ]
    },
    {
      "metadata": {
        "id": "lRkzM_4OFUJI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "metadata": {
        "id": "FMXzMDobFUJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "metadata": {
        "id": "Ho05oVTHFUJO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The environment"
      ]
    },
    {
      "metadata": {
        "id": "iKMprShVFUJP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "metadata": {
        "id": "102ARBtAFUJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYO522fUFUJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "metadata": {
        "id": "MFMkk4s_FUJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Agent"
      ]
    },
    {
      "metadata": {
        "id": "LBqGEMHiFUJa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "metadata": {
        "id": "43gCZPJAFUJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-sEOu_gQFUJg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "metadata": {
        "id": "iXYmhpSgFUJh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">  ```epsilon``` controls the capacity of the agent to explore more actions/states. We explore the environment with probability ```epsilon```, This parameter has to take in consideration a certain trade off , between exploration and exploitation, the more this parameter is big , the more we explore and the less we exploit already visited actions/states. In the other hand, if the parameter is small, we exploit more the already 'konwn' actions/states, and we don't explore more actions/states that can be more 'useful' for the agent. So the function act permits to exploit this epsilone greedy strategy where in a state s wether the agent chose a random action, or we chose an action already learned by the agent in that given state s."
      ]
    },
    {
      "metadata": {
        "id": "-AZK8j2YFUJj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "metadata": {
        "id": "eHtmf6L1FUJl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "48o8MDRPFUJm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "metadata": {
        "id": "R436vm4oFUJp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "metadata": {
        "id": "1iRRdJbBFUJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmV-M3CxFUJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "metadata": {
        "id": "h56WxlYJFUJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=45 # set small when debugging\n",
        "epochs_test=15 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5p0MrijAFUKC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "metadata": {
        "id": "ytveDMMaFUKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> **Board** corresponds to the matrix representing the positions where there is a bonus or a malus or nothing (because it's the sum of the sum of bonus and malus ).  The first state of the rat in the **board** is set to 0 which means that the rat will not start neither with a bonus or a malus. So **board** represents the reward distribution over the **NxN ** grid.\n",
        "\n",
        "> **Position** indicates the borders (the states that are not allowed to the agent and which are assigned to -1), the allowed states which are assigned to 0, and the current position of the agent which is assigent to 1. And that in each step of the game."
      ]
    },
    {
      "metadata": {
        "id": "PXjBn9zgFUKG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Agent"
      ]
    },
    {
      "metadata": {
        "id": "5PSEQzhLFUKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "metadata": {
        "id": "pWwY3g6jFUKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        action = np.random.randint(0, self.n_action, size=1)[0]\n",
        "        return action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JQwDNVfFUKM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "metadata": {
        "id": "dD1qhJsvFUKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\".format(win, lose, score/(1+e)))\n",
        "        \n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XodH1-gqFUKV",
        "colab_type": "code",
        "outputId": "6ee4527a-b88a-4d77-e5ef-be8dc7d7071f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 8.0/13.0. Average score (-5.0)\n",
            "Win/lose count 6.5/16.0. Average score (-7.25)\n",
            "Win/lose count 11.5/13.0. Average score (-5.333333333333333)\n",
            "Win/lose count 8.0/9.0. Average score (-4.25)\n",
            "Win/lose count 6.5/18.0. Average score (-5.7)\n",
            "Win/lose count 9.5/10.0. Average score (-4.833333333333333)\n",
            "Win/lose count 15.5/15.0. Average score (-4.071428571428571)\n",
            "Win/lose count 12.5/11.0. Average score (-3.375)\n",
            "Win/lose count 5.0/9.0. Average score (-3.4444444444444446)\n",
            "Win/lose count 12.5/15.0. Average score (-3.35)\n",
            "Win/lose count 4.5/13.0. Average score (-3.8181818181818183)\n",
            "Win/lose count 10.5/13.0. Average score (-3.7083333333333335)\n",
            "Win/lose count 6.0/15.0. Average score (-4.115384615384615)\n",
            "Win/lose count 8.0/10.0. Average score (-3.9642857142857144)\n",
            "Win/lose count 13.0/10.0. Average score (-3.5)\n",
            "Final score: -3.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "Y0qO8QQjFUKe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "metadata": {
        "id": "BtAx4XUkFUKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "s-zxEy9HFUKi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "> ** Let's show that ** :\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "We have : \n",
        "\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\\\ =  r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t=1}\\gamma^{t-1}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\\\ =r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t=0}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s',a_{0}=a'] \\\\ = r(s,a) +E_{(s',a')\\sim p(.|s,a)} [\\gamma E_{p^{\\pi}}[\\sum_{t=0}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']]  \\\\ = E_{(s',a')\\sim p(.|s,a)} [r(s,a) +\\gamma E_{p^{\\pi}}[\\sum_{t=0}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']] \\\\ Q^{\\pi}(s,a) =  E_{(s',a')\\sim p(.|s,a)} [r(s,a) +\\gamma Q^{\\pi}(s',a') ]\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "***\n",
        "> ** Let's show that ** :\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "We know that : \n",
        "\\begin{equation*}\n",
        "\\pi^{*}(s')=argmax_{a'} Q^* (s',a').\n",
        "\\end{equation*}\n",
        "\n",
        "So :\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')]. \\\\ = E_{s'\\sim p(.|s,a),a'\\sim \\pi^{*}(.|s')  }[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\\\\Q^{*}(s,a) = E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "\n",
        "***\n",
        "> ** Let's show that ** :\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "We have : \n",
        "\n",
        "$$Q^{*}(s,a) = E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].$$ \n",
        "\n",
        "which means that $Q^{*}$  verifies the following equality :\n",
        "\n",
        "\\begin{equation*}\n",
        "E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q(s',a') - Q(s,a)] = 0\n",
        "\\end{equation*}\n",
        "\n",
        "That means that  the optimal solution is reached by minimizing :\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}"
      ]
    },
    {
      "metadata": {
        "id": "8XQoVPm7FUKj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "metadata": {
        "id": "FocZeLYxFUKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory)>self.max_memory:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def random_access(self):\n",
        "        return random.choice(self.memory)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P6btGsOVFUK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "metadata": {
        "id": "vZ_qASeOFUK5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Npj5owa9FUK-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "metadata": {
        "id": "9yiO_4nRFUK_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s.reshape([1,s.shape[0],s.shape[1],s.shape[2]]))[0,:])\n",
        "\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            s_, n_s_, a_, r_, game_over_  = self.memory.random_access()\n",
        "            target_q[i] =self.model.predict(s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0]\n",
        "            # Save the current state\n",
        "            input_states[i] = s_\n",
        "            \n",
        "            # Modifying/updating the Q function\n",
        "            \n",
        "            \n",
        "            if game_over_:\n",
        "              #Only the reward is taken because ne next state \n",
        "              target_q[i,a_] = r_\n",
        "               \n",
        "               \n",
        "            else:\n",
        "              target_q[i,a_] = r_  + self.discount*max(self.model.predict(n_s_.reshape([1,s_.shape[0],s_.shape[1],s_.shape[2]]))[0])\n",
        "      \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.01,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        ####### FILL IN\n",
        "        model = Sequential()\n",
        "        # Flattening\n",
        "        model.add(Flatten(input_shape=(5,5,self.n_state,)))\n",
        "        # Using a single hidden layer \n",
        "        model.add(Dense(20,activation ='relu')) \n",
        "        # Fully connected ouptput layer \n",
        "        model.add(Dense(4)) # 4 possible actions\n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJldOYzKFULI",
        "colab_type": "code",
        "outputId": "4a49714a-6ae3-485b-c1bf-5737ce3d68c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1058
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train0.mp4'))\n",
        "#HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/045 | Loss 0.0273 | Win/lose count 3.5/10.0 (-6.5)\n",
            "Epoch 001/045 | Loss 0.0125 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 002/045 | Loss 0.0436 | Win/lose count 7.0/9.0 (-2.0)\n",
            "Epoch 003/045 | Loss 0.0083 | Win/lose count 4.0/5.0 (-1.0)\n",
            "Epoch 004/045 | Loss 0.0067 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 005/045 | Loss 0.0152 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 006/045 | Loss 0.0066 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 007/045 | Loss 0.0044 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 008/045 | Loss 0.0080 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 009/045 | Loss 0.0079 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 010/045 | Loss 0.0110 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 011/045 | Loss 0.0104 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 012/045 | Loss 0.0007 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 013/045 | Loss 0.0092 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 014/045 | Loss 0.0043 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 015/045 | Loss 0.0072 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 016/045 | Loss 0.0486 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 017/045 | Loss 0.0102 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 018/045 | Loss 0.0052 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 019/045 | Loss 0.0126 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 020/045 | Loss 0.0053 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 021/045 | Loss 0.0204 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 022/045 | Loss 0.0135 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 023/045 | Loss 0.0063 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 024/045 | Loss 0.0060 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 025/045 | Loss 0.0050 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 026/045 | Loss 0.0017 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 027/045 | Loss 0.0053 | Win/lose count 8.5/2.0 (6.5)\n",
            "Epoch 028/045 | Loss 0.0088 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 029/045 | Loss 0.0135 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 030/045 | Loss 0.0028 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 031/045 | Loss 0.0033 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 032/045 | Loss 0.0091 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 033/045 | Loss 0.0058 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 034/045 | Loss 0.0077 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 035/045 | Loss 0.0053 | Win/lose count 5.5/7.0 (-1.5)\n",
            "Epoch 036/045 | Loss 0.0036 | Win/lose count 8.5/4.0 (4.5)\n",
            "Epoch 037/045 | Loss 0.0061 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 038/045 | Loss 0.0030 | Win/lose count 12.5/3.0 (9.5)\n",
            "Epoch 039/045 | Loss 0.0063 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 040/045 | Loss 0.0052 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 041/045 | Loss 0.0050 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 042/045 | Loss 0.0024 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 043/045 | Loss 0.0531 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 044/045 | Loss 0.0056 | Win/lose count 5.0/1.0 (4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "qLHt5Dr-FULe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "metadata": {
        "id": "xgLtFrdeFULg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        model = Sequential()\n",
        "        \n",
        "        # A conv layer of kernel size 3 and 30 filters\n",
        "        model.add(Conv2D(30,(3,3),input_shape=(5,5,self.n_state,),activation='relu'))\n",
        "        \n",
        "        # A conv layer of kernel size 3 and 20 filters\n",
        "        model.add(Conv2D(20,(3,3),activation='relu'))\n",
        "        \n",
        "        # Flattening  the output\n",
        "        model.add(Flatten())\n",
        "        \n",
        "        # Flattening and feeding the output to a 4 units fully connected layer\n",
        "        model.add(Dense(4))\n",
        "    \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_dKoleTKFULl",
        "colab_type": "code",
        "outputId": "efa3c62d-86e2-4291-a23d-304476adf97e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "#HTML(display_videos('cnn_train0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/045 | Loss 0.0271 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 001/045 | Loss 0.0022 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 002/045 | Loss 0.0091 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 003/045 | Loss 0.0052 | Win/lose count 3.5/7.0 (-3.5)\n",
            "Epoch 004/045 | Loss 0.0101 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 005/045 | Loss 0.0073 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 006/045 | Loss 0.0903 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 007/045 | Loss 0.0057 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 008/045 | Loss 0.0022 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 009/045 | Loss 0.0040 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 010/045 | Loss 0.0024 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 011/045 | Loss 0.0027 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 012/045 | Loss 0.0030 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 013/045 | Loss 0.0049 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 014/045 | Loss 0.0012 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 015/045 | Loss 0.0011 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 016/045 | Loss 0.0516 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 017/045 | Loss 0.0022 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 018/045 | Loss 0.0019 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 019/045 | Loss 0.0042 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 020/045 | Loss 0.0022 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 021/045 | Loss 0.0028 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 022/045 | Loss 0.0053 | Win/lose count 13.0/0 (13.0)\n",
            "Epoch 023/045 | Loss 0.0277 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 024/045 | Loss 0.0008 | Win/lose count 9.0/1.0 (8.0)\n",
            "Epoch 025/045 | Loss 0.0020 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 026/045 | Loss 0.0024 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 027/045 | Loss 0.0402 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 028/045 | Loss 0.0030 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 029/045 | Loss 0.0029 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 030/045 | Loss 0.0024 | Win/lose count 9.5/2.0 (7.5)\n",
            "Epoch 031/045 | Loss 0.0034 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 032/045 | Loss 0.0040 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 033/045 | Loss 0.0034 | Win/lose count 8.5/2.0 (6.5)\n",
            "Epoch 034/045 | Loss 0.0025 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 035/045 | Loss 0.0013 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 036/045 | Loss 0.0027 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 037/045 | Loss 0.0020 | Win/lose count 9.5/1.0 (8.5)\n",
            "Epoch 038/045 | Loss 0.0023 | Win/lose count 15.0/2.0 (13.0)\n",
            "Epoch 039/045 | Loss 0.0456 | Win/lose count 12.0/0 (12.0)\n",
            "Epoch 040/045 | Loss 0.0015 | Win/lose count 11.0/3.0 (8.0)\n",
            "Epoch 041/045 | Loss 0.0042 | Win/lose count 18.0/4.0 (14.0)\n",
            "Epoch 042/045 | Loss 0.0026 | Win/lose count 7.5/2.0 (5.5)\n",
            "Epoch 043/045 | Loss 0.0036 | Win/lose count 11.0/3.0 (8.0)\n",
            "Epoch 044/045 | Loss 0.0012 | Win/lose count 9.0/1.0 (8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UtqSFujNeCdD",
        "colab_type": "code",
        "outputId": "9eb2aa10-3928-48ba-c291-e1e83a2fee6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "m-1OyosYFULu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "metadata": {
        "id": "omn7AJJOFULv",
        "colab_type": "code",
        "outputId": "e24458c9-ceed-44b3-f7ee-aeb29cdc21c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.5)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 9.5/5.0. Average score (4.5)\n",
            "Win/lose count 15.5/6.0. Average score (7.0)\n",
            "Win/lose count 21.0/4.0. Average score (10.333333333333334)\n",
            "Win/lose count 17.5/3.0. Average score (11.375)\n",
            "Win/lose count 14.0/9.0. Average score (10.1)\n",
            "Win/lose count 19.5/3.0. Average score (11.166666666666666)\n",
            "Win/lose count 14.0/6.0. Average score (10.714285714285714)\n",
            "Win/lose count 21.0/5.0. Average score (11.375)\n",
            "Win/lose count 12.0/5.0. Average score (10.88888888888889)\n",
            "Win/lose count 11.0/5.0. Average score (10.4)\n",
            "Win/lose count 8.0/3.0. Average score (9.909090909090908)\n",
            "Win/lose count 12.0/2.0. Average score (9.916666666666666)\n",
            "Win/lose count 4.5/0. Average score (9.5)\n",
            "Win/lose count 4.5/1.0. Average score (9.071428571428571)\n",
            "Win/lose count 20.0/5.0. Average score (9.466666666666667)\n",
            "Final score: 9.466666666666667\n",
            "Test of the FC\n",
            "Win/lose count 7.5/5.0. Average score (2.5)\n",
            "Win/lose count 12.0/12.0. Average score (1.25)\n",
            "Win/lose count 9.0/7.0. Average score (1.5)\n",
            "Win/lose count 7.0/4.0. Average score (1.875)\n",
            "Win/lose count 8.5/8.0. Average score (1.6)\n",
            "Win/lose count 3.5/10.0. Average score (0.25)\n",
            "Win/lose count 11.0/11.0. Average score (0.21428571428571427)\n",
            "Win/lose count 8.5/7.0. Average score (0.375)\n",
            "Win/lose count 12.5/5.0. Average score (1.1666666666666667)\n",
            "Win/lose count 5.5/3.0. Average score (1.3)\n",
            "Win/lose count 5.0/5.0. Average score (1.1818181818181819)\n",
            "Win/lose count 8.5/7.0. Average score (1.2083333333333333)\n",
            "Win/lose count 12.0/10.0. Average score (1.2692307692307692)\n",
            "Win/lose count 9.5/9.0. Average score (1.2142857142857142)\n",
            "Win/lose count 8.5/7.0. Average score (1.2333333333333334)\n",
            "Final score: 1.2333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ii8jBpy_FUL5",
        "colab_type": "code",
        "outputId": "793e6c64-e680-4e10-9941-d36f80512c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "XT2Lc8aTFUMB",
        "colab_type": "code",
        "outputId": "c7b18685-ed7b-4a7e-9e00-77153d255442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFwltZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALRZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpJw4v/ApLdW+BTLYTkVLmiBMA0DcSXTbQn+Il6+bSBN4IMWQUoYqarNv55+/p7ckvfbhrriHDDIaA8JRcvtxha0EOkTEvJnWIsM8CP/RE+VQk1N+CaPVpxlVk+cMz/oJZujBIOBkRhcgEpVRj2msAbSDmke+l1h8DcYO2Frf+ECFhV0Mf7aRl9qq2Ae6K2v4kLrVVrMZsM9bDursZkqYsewiHUUYuB6AcuwSqgf7qel72464dgTFcBNUFmaL4xcCmfZaxiYk1i4KcSUYMjeBE+UqbVRZ04YBNJfCuI6z1VFEjU6trNFwtNBR9NOdrYv9L5h4z15Jd8jCiYrZyGFumkNL+ga1j1yoFfWl58APcLb8gUUJZTUI8JfypZubVoH8By+58Qj4LdR0+IO/pJV7/ogQ9gm7exUojKx8l4/nWj+s4KfPTCDbfpROCASwgPGUMM2yJZr1KwftPuLuA+jUY7C/WTjrwh8AoRyXUzjy9mkxOAOIOWiccVwtCQTc7ed72+cxo97+jeLOfCtpKVmSIngwD4hgV0KzcgSr3OALH7kPCLDpaYKW/ZQAb4jyTvgHCrY2knOFqbqNG2IRq/OL6tEdtPJbWehNu0M8MHcApPBt19xWcKnSYh6nOIzip70RnrRdjbTJXX/Min2iUO74i7OZ9JwtA3TpwrNk7ar5QtdfbZyS4HSBn2nstWbQ2z9n7TL/G1pcku6SqqDMaCnRlEh7/lMUWyDDwtI7MMYCAz/chXVwm+OchlNB8h1poF0YON9hM9rlJRxkNJnSwoKEuYhyiDVA4aMpZlXrVRWUe6duUAmRRmQH2EwkQl5/cWuRnCUYmobJXgoXRMmdcVsQcBNnFTPPKI2plrL69UgUrBdpxEvxQAB9wAAABlBmiJsQ3/+p4QAHPJg4santzwPZZkc/A/qAAAADwGeQXkK/wAX6SzcGzapQwAAAB9BmkY8IZMphDf//qeEAGvpE/1I6zCAoe6Y5WBCfwtMAAAAEEGeZGpTwv8AP4nMc2lTNJEAAAAQAZ6DdEK/ADixiOA6ZTetgQAAAA8BnoVqQr8AWKNru+73nWEAAAAcQZqHSahBaJlMCHf//qmWACM/I6CGfv2QbioS4QAAABFBmqtJ4QpSZTAhv/6nhAABJwAAAAxBnslFNEwv/wAAsoAAAAAQAZ7odEK/ACRKkd+AD7etwQAAABABnupqQr8AJEqR3s8fb1uAAAAAGkGa7EmoQWiZTAh3//6plgAjCLDdFJnj+qxwAAAAF0GbD0nhClJlMCHf/qmWACM/Hn7+nNGBAAAAEkGfLUU0TCv/AFiwdd3gU1B4wQAAAA4Bn05qQr8AWJt14Da7rwAAABNBm1NJqEFomUwId//+qZYAAJWAAAAADEGfcUURLC//AACygAAAABABn5B0Qr8AJEqR34APt63BAAAAEAGfkmpCvwAkSpHezx9vW4AAAAATQZuXSahBbJlMCHf//qmWAACVgAAAAAxBn7VFFSwv/wAAsoEAAAAQAZ/UdEK/ACRKkd+AD7etwAAAABABn9ZqQr8AJEqR3s8fb1uBAAAAE0Gb20moQWyZTAh3//6plgAAlYEAAAAMQZ/5RRUsL/8AALKAAAAAEAGeGHRCvwAkSpHfgA+3rcEAAAAQAZ4aakK/ACRKkd7PH29bgAAAABNBmh9JqEFsmUwId//+qZYAAJWBAAAADEGePUUVLC//AACygQAAABABnlx0Qr8AJEqR34APt63AAAAAEAGeXmpCvwAkSpHezx9vW4AAAAATQZpDSahBbJlMCHf//qmWAACVgQAAAAxBnmFFFSwv/wAAsoAAAAAQAZ6AdEK/ACRKkd+AD7etwQAAABABnoJqQr8AJEqR3s8fb1uAAAAAE0Gah0moQWyZTAh3//6plgAAlYEAAAAMQZ6lRRUsL/8AALKBAAAAEAGexHRCvwAkSpHfgA+3rcEAAAAQAZ7GakK/ACRKkd7PH29bgQAAABNBmstJqEFsmUwId//+qZYAAJWAAAAADEGe6UUVLC//AACygAAAABABnwh0Qr8AJEqR34APt63BAAAAEAGfCmpCvwAkSpHezx9vW4AAAAATQZsPSahBbJlMCHf//qmWAACVgAAAAAxBny1FFSwv/wAAsoEAAAAQAZ9MdEK/ACRKkd+AD7etwQAAABABn05qQr8AJEqR3s8fb1uBAAAAE0GbU0moQWyZTAh3//6plgAAlYAAAAAMQZ9xRRUsL/8AALKAAAAAEAGfkHRCvwAkSpHfgA+3rcEAAAAQAZ+SakK/ACRKkd7PH29bgAAAABJBm5dJqEFsmUwIb//+p4QAAScAAAAMQZ+1RRUsL/8AALKBAAAAEAGf1HRCvwAkSpHfgA+3rcAAAAAQAZ/WakK/ACRKkd7PH29bgQAAABxBm9pJqEFsmUwIb//+p4QALnitIISiBO/6NfTBAAAAEkGf+EUVLCv/ACW7FewsF+Y9gAAAAA4BnhlqQr8AJbsmPOCF7QAAABxBmh1JqEFsmUwIb//+p4QAL66tHNf4qjmqGzG0AAAAEkGeO0UVLCv/ACa7FdyYOwEwCwAAABABnlxqQr8AJrs8tw2bU/uBAAAAGkGaXkmoQWyZTAhv//6nhABJUAWbYgDSGqzAAAAAGEGaf0nhClJlMCHf/qmWADjpkJNrs4ahcAAAABJBmoNJ4Q6JlMCHf/6plgAAlYEAAAAMQZ6hRRE8L/8AALKAAAAAEAGewHRCvwBdOgHQsYnFshEAAAAQAZ7CakK/AF0jc4XSSkxZCAAAABNBmsdJqEFomUwId//+qZYAAJWBAAAADEGe5UURLC//AACygQAAABABnwR0Qr8AXToGwZxicWyFAAAAEAGfBmpCvwBdI3OF0kpMWQkAAAATQZsLSahBbJlMCHf//qmWAACVgAAAAAxBnylFFSwv/wAAsoAAAAAQAZ9IdEK/AF06BsGcYnFshQAAABABn0pqQr8AXSNzhdJKTFkIAAAAF0GbT0moQWyZTAh3//6plgBZvfV9zz/AAAAADkGfbUUVLC//AGmVbZlRAAAAEAGfjHRCvwBdOgbBnGJxbIUAAAAQAZ+OakK/AI7a13eST7KiwQAAABNBm5NJqEFsmUwId//+qZYAAJWAAAAADEGfsUUVLC//AACygAAAABABn9B0Qr8AXCyjvwAfbtfBAAAAEAGf0mpCvwBcLKO9nj7dr4AAAAAcQZvXSahBbJlMCHf//qmWADk+0v7FgOiBbjF/MgAAABBBn/VFFSwv/wBDc/c4WUZJAAAADwGeFHRCvwBdIxi4D8tkIAAAABABnhZqQr8AXRuQw+gJBxrZAAAAF0GaG0moQWyZTAh3//6plgAYz4Ufc/phAAAAFUGeOUUVLC//AC14qN3RPYfu1ha2YAAAABABnlh0Qr8APLxRcB9nMkFhAAAAEAGeWmpCvwA8zPAuv1ikgsAAAAATQZpfSahBbJlMCHf//qmWAACVgQAAABBBnn1FFSwv/wAteS2b9H13AAAAEAGenHRCvwA8vFFwH2cyQWAAAAAQAZ6eakK/ADzM8C6/WKSCwAAAABNBmoNJqEFsmUwId//+qZYAAJWBAAAAEEGeoUUVLC//AC15LZv0fXYAAAAQAZ7AdEK/ADy8UXAfZzJBYQAAABABnsJqQr8APMzwLr9YpILAAAAAE0Gax0moQWyZTAh3//6plgAAlYEAAAAQQZ7lRRUsL/8ALXktm/R9dwAAABABnwR0Qr8APLxRcB9nMkFhAAAAEAGfBmpCvwA8zPAuv1ikgsEAAAATQZsLSahBbJlMCHf//qmWAACVgAAAABBBnylFFSwv/wAteS2b9H12AAAAEAGfSHRCvwA8vFFwH2cyQWEAAAAQAZ9KakK/ADzM8C6/WKSCwAAAABNBm09JqEFsmUwId//+qZYAAJWAAAAAEEGfbUUVLC//AC15LZv0fXcAAAAQAZ+MdEK/ADy8UXAfZzJBYQAAABABn45qQr8APMzwLr9YpILBAAAAE0Gbk0moQWyZTAh3//6plgAAlYAAAAAQQZ+xRRUsL/8ALXktm/R9dgAAABABn9B0Qr8APLxRcB9nMkFhAAAAEAGf0mpCvwA8zPAuv1ikgsAAAAATQZvXSahBbJlMCHf//qmWAACVgAAAABBBn/VFFSwv/wAteS2b9H13AAAAEAGeFHRCvwA8vFFwH2cyQWAAAAAQAZ4WakK/ADzM8C6/WKSCwQAAABNBmhtJqEFsmUwId//+qZYAAJWBAAAAEEGeOUUVLC//AC15LZv0fXYAAAAQAZ5YdEK/ADy8UXAfZzJBYQAAABABnlpqQr8APMzwLr9YpILAAAAAE0GaX0moQWyZTAh3//6plgAAlYEAAAAQQZ59RRUsL/8ALXktm/R9dwAAABABnpx0Qr8APLxRcB9nMkFgAAAAEAGenmpCvwA8zPAuv1ikgsAAAAATQZqDSahBbJlMCHf//qmWAACVgQAAABBBnqFFFSwv/wAteS2b9H12AAAAEAGewHRCvwA8vFFwH2cyQWEAAAAQAZ7CakK/ADzM8C6/WKSCwAAAABNBmsdJqEFsmUwId//+qZYAAJWBAAAAEEGe5UUVLC//AC15LZv0fXcAAAAQAZ8EdEK/ADy8UXAfZzJBYQAAABABnwZqQr8APMzwLr9YpILBAAAAGUGbCkmoQWyZTAh3//6plgAmCpwAMOn1S8AAAAAPQZ8oRRUsK/8APMD/moUgAAAADwGfSWpCvwAn3KB5MEZPgQAAABtBm05JqEFsmUwIb//+p4QAc9i2s24Fvjp5H3QAAAAQQZ9sRRUsL/8ARXP0HKHXBAAAAA8Bn4t0Qr8AJ9GEBklzE4EAAAAQAZ+NakK/AF+dqOV/bh9yQQAAAB9Bm5FJqEFsmUwIb//+p4QAdH4DA3P575ohcUJAgU+BAAAAHkGfr0UVLCv/AGD0sPAppE2HMr0WnMserbm18FmMwAAAAA8Bn9BqQr8AYglpUigSqh4AAAAaQZvSSahBbJlMCG///qeEAEu+On1HGhIcWUEAAAAcQZv0SeEKUmUwUVLDv/6plgAnCgn5W/32l9z8cAAAABABnhNqQr8APizwh40NY52AAAAAEUGaGEnhDomUwIb//qeEAAEnAAAADEGeNkUVPC//AACygAAAABABnlV0Qr8AYiyru+obuEvxAAAAEAGeV2pCvwA9ihvYrR9u/kEAAAAZQZpbSahBaJlMCG///qeEAE2+OmP8Pq23QwAAABJBnnlFESwr/wBiIaXd39IrZcEAAAAOAZ6aakK/AGIJcZg4Gy4AAAAaQZqcSahBbJlMCG///qeEAEu+On1HGhIcWUEAAAAcQZq+SeEKUmUwUVLDf/6nhABNUvaQZlvon6FyQQAAABABnt1qQr8APizwh40NY52AAAAAF0GawUnhDomUwIb//qeEAE2+OmbAoK+9AAAAEkGe/0UVPCv/AGIhpd3f0itlwQAAAA4BnwBqQr8AYglxmDgbLgAAABpBmwJJqEFomUwIb//+p4QAS746fUcaEhxZQQAAABxBmyRJ4QpSZTBREsN//qeEAE1S9pBmW+ifoXJAAAAAEAGfQ2pCvwA+LPCHjQ1jnYEAAAAXQZtHSeEOiZTAhv/+p4QATb46ZsCgr70AAAASQZ9lRRU8K/8AYiGl3d/SK2XBAAAADgGfhmpCvwBiCXGYOBsvAAAAGkGbiEmoQWiZTAhv//6nhABLvjp9RxoSHFlAAAAAHEGbqknhClJlMFESw3/+p4QATVL2kGZb6J+hckAAAAAQAZ/JakK/AD4s8IeNDWOdgQAAABdBm81J4Q6JlMCG//6nhABNvjpmwKCvvQAAABJBn+tFFTwr/wBiIaXd39IrZcAAAAAOAZ4MakK/AGIJcZg4Gy8AAAAaQZoOSahBaJlMCG///qeEAEu+On1HGhIcWUEAAAAcQZowSeEKUmUwURLDv/6plgAnCgn5W/32l9z8cQAAABABnk9qQr8APizwh40NY52AAAAAEUGaVEnhDomUwIb//qeEAAEnAAAADEGeckUVPC//AACygQAAABABnpF0Qr8AYiyru+obuEvwAAAAEAGek2pCvwA9ihvYrR9u/kAAAAAZQZqXSahBaJlMCG///qeEAE2+OmP8Pq23QwAAABJBnrVFESwr/wBiIaXd39IrZcAAAAAOAZ7WakK/AGIJcZg4Gy8AAAAaQZrYSahBbJlMCG///qeEAEu+On1HGhIcWUEAAAAcQZr6SeEKUmUwUVLDf/6nhABNUvaQZlvon6FyQAAAABABnxlqQr8APizwh40NY52BAAAAF0GbHUnhDomUwIb//qeEAE2+OmbAoK+9AAAAEkGfO0UVPCv/AGIhpd3f0itlwQAAAA4Bn1xqQr8AYglxmDgbLwAAABpBm15JqEFomUwIb//+p4QAS746fUcaEhxZQAAAABxBm2BJ4QpSZTBREsN//qeEAE1S9pBmW+ifoXJAAAAAEAGfn2pCvwA+LPCHjQ1jnYEAAAAXQZuDSeEOiZTAhn/+nhABLviHqH36PvQAAAASQZ+hRRU8K/8AYiGl3d/SK2XBAAAADgGfwmpCvwBiCXGYOBsuAAAAGUGbxEmoQWiZTAhn//6eEAEm+If2yGPrCXcAAAAbQZvmSeEKUmUwURLDP/6eEAEtQ/xpFG+IfnJJAAAAEAGeBWpCvwA+LPCHjQ1jnYEAAAAaQZoJS+EIQ6JEYIKAfyAf2HgCFf/+OEAAEXEAAAAnQZ4nRRU8K/8Cr2PtQcTdqsNJJuWqhgcstxIivQw/SXN0Xl16hOiwAAAAIwGeSGpCvwKvY+1BxN2qw0km5aqGByy3Eyjw2UnLSqobhcvAAAAMGG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAtCdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKum1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACmVtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAolc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXwY3R0cwAAAAAAAAC8AAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABYYAAAAdAAAAEwAAACMAAAAUAAAAFAAAABMAAAAgAAAAFQAAABAAAAAUAAAAFAAAAB4AAAAbAAAAFgAAABIAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAIAAAABYAAAASAAAAIAAAABYAAAAUAAAAHgAAABwAAAAWAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAbAAAAEgAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAACAAAAAUAAAAEwAAABQAAAAbAAAAGQAAABQAAAAUAAAAFwAAABQAAAAUAAAAFAAAABcAAAAUAAAAFAAAABQAAAAXAAAAFAAAABQAAAAUAAAAFwAAABQAAAAUAAAAFAAAABcAAAAUAAAAFAAAABQAAAAXAAAAFAAAABQAAAAUAAAAFwAAABQAAAAUAAAAFAAAABcAAAAUAAAAFAAAABQAAAAXAAAAFAAAABQAAAAUAAAAFwAAABQAAAAUAAAAFAAAABcAAAAUAAAAFAAAABQAAAAdAAAAEwAAABMAAAAfAAAAFAAAABMAAAAUAAAAIwAAACIAAAATAAAAHgAAACAAAAAUAAAAFQAAABAAAAAUAAAAFAAAAB0AAAAWAAAAEgAAAB4AAAAgAAAAFAAAABsAAAAWAAAAEgAAAB4AAAAgAAAAFAAAABsAAAAWAAAAEgAAAB4AAAAgAAAAFAAAABsAAAAWAAAAEgAAAB4AAAAgAAAAFAAAABUAAAAQAAAAFAAAABQAAAAdAAAAFgAAABIAAAAeAAAAIAAAABQAAAAbAAAAFgAAABIAAAAeAAAAIAAAABQAAAAbAAAAFgAAABIAAAAdAAAAHwAAABQAAAAeAAAAKwAAACcAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "tv6sHnzpFUMM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> ** Observation and comment** : The issues that we observe are that the agent get stuck in an area of the grid if he is not \"surrounded\" by a positive cell (not in his visibility). And this case is specially observed fo the fully connected architecture.\n",
        "\n",
        "> ** Effect of temperature** Increasing the temperature means increasing the number of positive cells which means that the agent gets to explore the map easily than a smaller value because he will be surrounded by more positive cells, which means a better final verage score."
      ]
    },
    {
      "metadata": {
        "id": "q0S2T9wzFUMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E8m8K8eyFUMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_explore(agent,env,epoch,decay = 0.1,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    \n",
        "    # Starting the value of epsilone\n",
        "    \n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        \n",
        "        agent.set_epsilon(agent.epsilon*(1-decay))\n",
        "        \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action,train = True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "    \n",
        "    \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "        # apply a malus if thethe agent visit an already visited cell \n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "        \n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action, train = False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "            \n",
        "        \n",
        "        self.t = self.t + 1\n",
        "        \n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "        \n",
        "        r = 0\n",
        "        if train:\n",
        "            r = -self.malus_position[self.x, self.y]\n",
        "            \n",
        "        reward = self.board[self.x, self.y] + r \n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        \n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2) \n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NI_1EjnoFUMm",
        "colab_type": "code",
        "outputId": "c0f6339b-c474-42a5-cce6-ee36aea33737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "# Parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=100\n",
        "epochs_test=15\n",
        "\n",
        "\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.7, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/100 | Loss 0.0144 | Win/lose count 9.600000000000003/24.700000000000088 (-15.100000000000085)\n",
            "Epoch 001/100 | Loss 0.0292 | Win/lose count 5.2/26.800000000000093 (-21.600000000000094)\n",
            "Epoch 002/100 | Loss 0.0059 | Win/lose count 2.8/29.400000000000123 (-26.600000000000122)\n",
            "Epoch 003/100 | Loss 0.0083 | Win/lose count 10.000000000000004/22.600000000000065 (-12.600000000000062)\n",
            "Epoch 004/100 | Loss 0.0154 | Win/lose count 2.0/21.60000000000004 (-19.60000000000004)\n",
            "Epoch 005/100 | Loss 0.0054 | Win/lose count 5.6000000000000005/28.700000000000117 (-23.100000000000115)\n",
            "Epoch 006/100 | Loss 0.0060 | Win/lose count 5.2/24.80000000000005 (-19.60000000000005)\n",
            "Epoch 007/100 | Loss 0.0104 | Win/lose count 6.400000000000001/22.50000000000005 (-16.100000000000048)\n",
            "Epoch 008/100 | Loss 0.0081 | Win/lose count 7.200000000000002/21.300000000000043 (-14.10000000000004)\n",
            "Epoch 009/100 | Loss 0.0171 | Win/lose count 16.800000000000004/21.900000000000055 (-5.100000000000051)\n",
            "Epoch 010/100 | Loss 0.0057 | Win/lose count 3.5999999999999996/22.200000000000035 (-18.600000000000037)\n",
            "Epoch 011/100 | Loss 0.0061 | Win/lose count 10.400000000000004/21.500000000000025 (-11.100000000000021)\n",
            "Epoch 012/100 | Loss 0.0032 | Win/lose count 8.000000000000002/20.100000000000005 (-12.100000000000003)\n",
            "Epoch 013/100 | Loss 0.0035 | Win/lose count 10.000000000000004/20.600000000000012 (-10.600000000000009)\n",
            "Epoch 014/100 | Loss 0.0033 | Win/lose count 10.400000000000004/24.50000000000008 (-14.100000000000078)\n",
            "Epoch 015/100 | Loss 0.0062 | Win/lose count 4.8/20.900000000000027 (-16.100000000000026)\n",
            "Epoch 016/100 | Loss 0.0038 | Win/lose count 6.400000000000001/19.500000000000007 (-13.100000000000005)\n",
            "Epoch 017/100 | Loss 0.0070 | Win/lose count 10.800000000000004/19.39999999999999 (-8.599999999999987)\n",
            "Epoch 018/100 | Loss 0.0046 | Win/lose count 8.000000000000002/22.100000000000033 (-14.100000000000032)\n",
            "Epoch 019/100 | Loss 0.0074 | Win/lose count 20.79999999999999/17.89999999999999 (2.8999999999999986)\n",
            "Epoch 020/100 | Loss 0.0064 | Win/lose count 12.400000000000006/21.000000000000036 (-8.60000000000003)\n",
            "Epoch 021/100 | Loss 0.0023 | Win/lose count 7.600000000000002/18.19999999999999 (-10.599999999999987)\n",
            "Epoch 022/100 | Loss 0.0084 | Win/lose count 14.800000000000008/17.39999999999998 (-2.599999999999973)\n",
            "Epoch 023/100 | Loss 0.0080 | Win/lose count 10.400000000000004/21.500000000000032 (-11.100000000000028)\n",
            "Epoch 024/100 | Loss 0.0185 | Win/lose count 16.800000000000004/18.89999999999999 (-2.099999999999987)\n",
            "Epoch 025/100 | Loss 0.0229 | Win/lose count 6.000000000000001/18.599999999999994 (-12.599999999999994)\n",
            "Epoch 026/100 | Loss 0.0047 | Win/lose count 19.599999999999994/17.19999999999998 (2.400000000000013)\n",
            "Epoch 027/100 | Loss 0.0315 | Win/lose count 9.600000000000003/17.69999999999998 (-8.099999999999978)\n",
            "Epoch 028/100 | Loss 0.0099 | Win/lose count 15.600000000000009/17.199999999999974 (-1.599999999999966)\n",
            "Epoch 029/100 | Loss 0.0099 | Win/lose count 18.799999999999997/16.399999999999967 (2.4000000000000306)\n",
            "Epoch 030/100 | Loss 0.0257 | Win/lose count 8.800000000000002/17.899999999999984 (-9.099999999999982)\n",
            "Epoch 031/100 | Loss 0.0190 | Win/lose count 9.600000000000003/17.69999999999998 (-8.099999999999978)\n",
            "Epoch 032/100 | Loss 0.0234 | Win/lose count 12.800000000000006/16.89999999999997 (-4.099999999999964)\n",
            "Epoch 033/100 | Loss 0.0117 | Win/lose count 9.600000000000003/17.69999999999998 (-8.099999999999978)\n",
            "Epoch 034/100 | Loss 0.0107 | Win/lose count 9.600000000000003/17.69999999999998 (-8.099999999999978)\n",
            "Epoch 035/100 | Loss 0.0161 | Win/lose count 14.800000000000008/16.399999999999963 (-1.5999999999999552)\n",
            "Epoch 036/100 | Loss 0.0104 | Win/lose count 15.200000000000008/17.29999999999998 (-2.0999999999999712)\n",
            "Epoch 037/100 | Loss 0.0158 | Win/lose count 4.3999999999999995/19.0 (-14.600000000000001)\n",
            "Epoch 038/100 | Loss 0.0156 | Win/lose count 6.400000000000001/18.499999999999993 (-12.09999999999999)\n",
            "Epoch 039/100 | Loss 0.0080 | Win/lose count 13.200000000000006/16.79999999999997 (-3.5999999999999623)\n",
            "Epoch 040/100 | Loss 0.0142 | Win/lose count 15.600000000000009/18.199999999999992 (-2.5999999999999837)\n",
            "Epoch 041/100 | Loss 0.0125 | Win/lose count 15.600000000000009/17.199999999999978 (-1.5999999999999694)\n",
            "Epoch 042/100 | Loss 0.0092 | Win/lose count 10.800000000000004/17.399999999999977 (-6.599999999999973)\n",
            "Epoch 043/100 | Loss 0.0235 | Win/lose count 11.600000000000005/17.199999999999974 (-5.5999999999999694)\n",
            "Epoch 044/100 | Loss 0.0199 | Win/lose count 11.200000000000005/19.300000000000008 (-8.100000000000003)\n",
            "Epoch 045/100 | Loss 0.0153 | Win/lose count 14.000000000000007/18.599999999999998 (-4.599999999999991)\n",
            "Epoch 046/100 | Loss 0.0140 | Win/lose count 9.600000000000003/17.69999999999998 (-8.099999999999978)\n",
            "Epoch 047/100 | Loss 0.0220 | Win/lose count 13.600000000000007/16.699999999999967 (-3.0999999999999606)\n",
            "Epoch 048/100 | Loss 0.0094 | Win/lose count 14.000000000000007/17.599999999999984 (-3.5999999999999766)\n",
            "Epoch 049/100 | Loss 0.0185 | Win/lose count 12.000000000000005/17.099999999999973 (-5.099999999999968)\n",
            "Epoch 050/100 | Loss 0.0114 | Win/lose count 8.000000000000002/18.099999999999987 (-10.099999999999985)\n",
            "Epoch 051/100 | Loss 0.0133 | Win/lose count 12.000000000000005/18.09999999999999 (-6.099999999999985)\n",
            "Epoch 052/100 | Loss 0.0099 | Win/lose count 14.800000000000008/18.399999999999995 (-3.599999999999987)\n",
            "Epoch 053/100 | Loss 0.0154 | Win/lose count 16.000000000000007/17.099999999999973 (-1.099999999999966)\n",
            "Epoch 054/100 | Loss 0.0178 | Win/lose count 12.800000000000006/18.900000000000006 (-6.1)\n",
            "Epoch 055/100 | Loss 0.0127 | Win/lose count 11.200000000000005/17.299999999999976 (-6.099999999999971)\n",
            "Epoch 056/100 | Loss 0.0110 | Win/lose count 6.400000000000001/18.499999999999993 (-12.09999999999999)\n",
            "Epoch 057/100 | Loss 0.0071 | Win/lose count 15.200000000000008/19.300000000000008 (-4.1)\n",
            "Epoch 058/100 | Loss 0.0140 | Win/lose count 13.600000000000007/16.699999999999967 (-3.0999999999999606)\n",
            "Epoch 059/100 | Loss 0.0269 | Win/lose count 12.000000000000005/18.09999999999999 (-6.099999999999985)\n",
            "Epoch 060/100 | Loss 0.0158 | Win/lose count 7.200000000000002/19.300000000000004 (-12.100000000000001)\n",
            "Epoch 061/100 | Loss 0.0588 | Win/lose count 14.400000000000007/17.49999999999998 (-3.0999999999999712)\n",
            "Epoch 062/100 | Loss 0.0290 | Win/lose count 10.400000000000004/18.499999999999996 (-8.099999999999993)\n",
            "Epoch 063/100 | Loss 0.0258 | Win/lose count 18.799999999999997/15.399999999999961 (3.400000000000036)\n",
            "Epoch 064/100 | Loss 0.0132 | Win/lose count 14.400000000000007/17.499999999999982 (-3.0999999999999748)\n",
            "Epoch 065/100 | Loss 0.0134 | Win/lose count 17.200000000000003/15.79999999999996 (1.400000000000043)\n",
            "Epoch 066/100 | Loss 0.0206 | Win/lose count 16.800000000000004/17.899999999999974 (-1.0999999999999694)\n",
            "Epoch 067/100 | Loss 0.0137 | Win/lose count 10.400000000000004/18.499999999999993 (-8.099999999999989)\n",
            "Epoch 068/100 | Loss 0.0344 | Win/lose count 2.8/19.400000000000006 (-16.600000000000005)\n",
            "Epoch 069/100 | Loss 0.0089 | Win/lose count 16.000000000000007/17.099999999999973 (-1.099999999999966)\n",
            "Epoch 070/100 | Loss 0.0191 | Win/lose count 11.200000000000005/17.299999999999976 (-6.099999999999971)\n",
            "Epoch 071/100 | Loss 0.0140 | Win/lose count 12.000000000000005/18.099999999999987 (-6.099999999999982)\n",
            "Epoch 072/100 | Loss 0.0153 | Win/lose count 12.800000000000006/18.900000000000006 (-6.1)\n",
            "Epoch 073/100 | Loss 0.0240 | Win/lose count 21.19999999999999/16.799999999999976 (4.400000000000013)\n",
            "Epoch 074/100 | Loss 0.0324 | Win/lose count 14.400000000000007/17.49999999999998 (-3.0999999999999712)\n",
            "Epoch 075/100 | Loss 0.0079 | Win/lose count 15.600000000000009/20.20000000000001 (-4.600000000000001)\n",
            "Epoch 076/100 | Loss 0.0236 | Win/lose count 8.000000000000002/19.1 (-11.1)\n",
            "Epoch 077/100 | Loss 0.0144 | Win/lose count 18.4/18.499999999999996 (-0.09999999999999787)\n",
            "Epoch 078/100 | Loss 0.0217 | Win/lose count 14.000000000000007/17.599999999999984 (-3.5999999999999766)\n",
            "Epoch 079/100 | Loss 0.0129 | Win/lose count 14.400000000000007/18.5 (-4.0999999999999925)\n",
            "Epoch 080/100 | Loss 0.0140 | Win/lose count 14.800000000000008/16.399999999999963 (-1.5999999999999552)\n",
            "Epoch 081/100 | Loss 0.0306 | Win/lose count 12.000000000000005/18.099999999999987 (-6.099999999999982)\n",
            "Epoch 082/100 | Loss 0.0073 | Win/lose count 15.600000000000009/21.200000000000045 (-5.600000000000037)\n",
            "Epoch 083/100 | Loss 0.0147 | Win/lose count 8.000000000000002/20.10000000000002 (-12.100000000000017)\n",
            "Epoch 084/100 | Loss 0.0089 | Win/lose count 14.800000000000008/16.399999999999963 (-1.5999999999999552)\n",
            "Epoch 085/100 | Loss 0.0117 | Win/lose count 14.000000000000007/17.599999999999984 (-3.5999999999999766)\n",
            "Epoch 086/100 | Loss 0.0148 | Win/lose count 16.800000000000004/17.89999999999999 (-1.0999999999999872)\n",
            "Epoch 087/100 | Loss 0.0246 | Win/lose count 6.000000000000001/18.599999999999994 (-12.599999999999994)\n",
            "Epoch 088/100 | Loss 0.0306 | Win/lose count 9.600000000000003/18.7 (-9.099999999999996)\n",
            "Epoch 089/100 | Loss 0.0216 | Win/lose count 15.200000000000008/18.299999999999994 (-3.0999999999999854)\n",
            "Epoch 090/100 | Loss 0.0118 | Win/lose count 13.200000000000006/17.799999999999986 (-4.59999999999998)\n",
            "Epoch 091/100 | Loss 0.0287 | Win/lose count 20.39999999999999/15.999999999999963 (4.400000000000029)\n",
            "Epoch 092/100 | Loss 0.0094 | Win/lose count 15.200000000000008/17.29999999999998 (-2.0999999999999712)\n",
            "Epoch 093/100 | Loss 0.0200 | Win/lose count 10.000000000000004/17.59999999999998 (-7.5999999999999766)\n",
            "Epoch 094/100 | Loss 0.0126 | Win/lose count 10.000000000000004/18.599999999999994 (-8.59999999999999)\n",
            "Epoch 095/100 | Loss 0.0162 | Win/lose count 10.800000000000004/18.39999999999999 (-7.599999999999987)\n",
            "Epoch 096/100 | Loss 0.0396 | Win/lose count 11.200000000000005/17.299999999999976 (-6.099999999999971)\n",
            "Epoch 097/100 | Loss 0.0084 | Win/lose count 12.000000000000005/19.10000000000001 (-7.100000000000003)\n",
            "Epoch 098/100 | Loss 0.0139 | Win/lose count 14.000000000000007/21.60000000000005 (-7.600000000000044)\n",
            "Epoch 099/100 | Loss 0.0118 | Win/lose count 15.600000000000009/18.199999999999996 (-2.599999999999987)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wr8_yL2yuTLO",
        "colab_type": "code",
        "outputId": "36bcb5a0-d149-4e38-f675-e234687c5eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "oIzQRWuaFUMy",
        "colab_type": "code",
        "outputId": "268d87c7-615a-462c-fdb8-7ca2d56373b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore14.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 16.0/2.0. Average score (14.0)\n",
            "Win/lose count 8.5/0. Average score (11.25)\n",
            "Win/lose count 15.0/1.0. Average score (12.166666666666666)\n",
            "Win/lose count 12.0/0. Average score (12.125)\n",
            "Win/lose count 17.5/2.0. Average score (12.8)\n",
            "Win/lose count 1.5/0. Average score (10.916666666666666)\n",
            "Win/lose count 9.5/2.0. Average score (10.428571428571429)\n",
            "Win/lose count 16.5/0. Average score (11.1875)\n",
            "Win/lose count 23.5/2.0. Average score (12.333333333333334)\n",
            "Win/lose count 15.5/3.0. Average score (12.35)\n",
            "Win/lose count 13.0/2.0. Average score (12.227272727272727)\n",
            "Win/lose count 10.5/2.0. Average score (11.916666666666666)\n",
            "Win/lose count 20.5/3.0. Average score (12.346153846153847)\n",
            "Win/lose count 20.0/3.0. Average score (12.678571428571429)\n",
            "Win/lose count 6.5/1.0. Average score (12.2)\n",
            "Final score: 12.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "SNDXKHp4DL6W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Indeed the agent explores more areas in the map and we have a good final score. which means that the epsilone greedy strategy works well with this kind of problems."
      ]
    },
    {
      "metadata": {
        "id": "_Sy3KuxEFUM8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "metadata": {
        "id": "SRfypxwSFUM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "7ZSvDZGbFUNA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    }
  ]
}